{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90fbd34",
   "metadata": {},
   "source": [
    "# 실습: Azure AI Search와 OpenAI 임베딩을 활용한 RAG 구현\n",
    "\n",
    "\n",
    "## 왜 RAG(Retrieval Augmented Generation)가 필요한가?\n",
    "\n",
    "\n",
    "기존의 대형 언어 모델(LLM)은 사전 학습된 지식만을 바탕으로 답변을 생성하기 때문에, 최신 정보나 특정 도메인 데이터에 대한 답변이 부정확하거나 제한적일 수 있습니다. RAG는 외부 데이터베이스(예: 사내 문서, 최신 자료 등)에서 관련 정보를 검색(Retrieval)한 뒤, 이를 LLM의 입력 컨텍스트로 활용하여 보다 정확하고 신뢰할 수 있는 답변을 생성(Generation)하는 방식입니다.\n",
    "\n",
    "\n",
    "- **최신성**: LLM이 알지 못하는 최신 정보나 사내 데이터도 답변에 반영할 수 있습니다.\n",
    "- **정확성**: 검색된 실제 문서를 근거로 답변을 생성하므로, 신뢰도와 근거 기반 답변이 강화됩니다.\n",
    "- **확장성**: 다양한 데이터 소스와 결합하여, 특정 도메인이나 업무에 특화된 AI 서비스를 쉽게 구축할 수 있습니다.\n",
    "\n",
    "\n",
    "이 노트북에서는 JSON 데이터를 Azure AI Search에 업로드하고, Azure OpenAI의 임베딩 API를 활용해 벡터 인덱싱을 수행한 뒤, 이를 기반으로 간단한 RAG를 구현하는 과정을 단계별로 실습합니다.\n",
    "\n",
    "\n",
    "- Azure AI Search 및 OpenAI 리소스 준비\n",
    "- JSON 데이터 업로드 및 인덱스 생성\n",
    "- 임베딩 생성 및 저장\n",
    "- 자연어 쿼리로 검색\n",
    "- 간단한 RAG 구현\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3c1f0",
   "metadata": {},
   "source": [
    "## 1. Azure 리소스 생성\n",
    "\n",
    "이 실습을 위해서는 다음과 같은 Azure 리소스가 필요합니다. 각 리소스는 RAG (Retrieval Augmented Generation) 파이프라인의 특정 단계를 수행하는 데 사용됩니다.\n",
    "\n",
    "1.  **Azure Blob Storage 계정 및 컨테이너**:\n",
    "    *   **목적**: 원본 데이터(이 실습에서는 `sample.json` 파일)를 저장합니다. Azure AI Search가 이 데이터를 읽어 인덱싱을 수행합니다.\n",
    "    *   **필요성**: 대량의 데이터를 안정적으로 저장하고, 다른 Azure 서비스에서 쉽게 접근할 수 있도록 하기 위함입니다.\n",
    "\n",
    "2.  **Azure AI Search 서비스**:\n",
    "    *   **목적**: 업로드된 JSON 데이터에 대한 검색 인덱스를 생성하고 관리합니다. 특히, 텍스트 데이터로부터 생성된 벡터 임베딩을 저장하고, 이를 기반으로 유사도 검색(벡터 검색)을 수행하는 데 핵심적인 역할을 합니다.\n",
    "    *   **필요성**: RAG의 'Retrieval' 단계를 담당하여, 사용자 질문과 관련된 정보를 효율적으로 찾아내기 위함입니다.\n",
    "\n",
    "3.  **Azure OpenAI 서비스**:\n",
    "    *   **목적**:\n",
    "        *   **임베딩 모델 배포 (예: `text-embedding-3-large`)**: JSON 데이터의 텍스트 내용을 숫자 벡터(임베딩)로 변환하여 Azure AI Search 인덱스에 저장합니다. 또한, 사용자 질문도 임베딩으로 변환하여 검색에 사용합니다.\n",
    "        *   **채팅 모델 배포 (예: `gpt-4.1-mini`, `gpt-4o-mini`)**: Azure AI Search를 통해 검색된 관련 문서를 컨텍스트로 활용하여, 사용자의 질문에 대한 최종 답변을 생성합니다 (RAG의 'Generation' 단계).\n",
    "    *   **필요성**: 데이터의 의미를 이해하고(임베딩), 검색된 정보를 바탕으로 자연스러운 답변을 생성하기(LLM) 위함입니다.\n",
    "\n",
    "**Azure 리소스 생성 참고:**\n",
    "1. [Azure Blob Storage 계정 및 컨테이너 생성 가이드](https://learn.microsoft.com/azure/storage/blobs/storage-quickstart-blobs-portal)\n",
    "2. [Azure AI Search 서비스 생성 가이드](https://learn.microsoft.com/azure/search/search-create-service-portal)\n",
    "3. [Azure OpenAI 서비스 리소스 생성 및 모델 배포 가이드](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal) (이 실습에서는 임베딩 모델과 채팅 모델 두 가지를 배포해야 합니다.)\n",
    "\n",
    "> 참고: [Azure AI Search 공식 문서](https://learn.microsoft.com/azure/search/search-what-is-azure-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc840134",
   "metadata": {},
   "source": [
    "### [중요] Azure 리소스 변수 선언\n",
    "\n",
    "아래 코드셀에서는 Azure 리소스(리소스 그룹, 위치, 스토리지 계정, 컨테이너, AI Search 서비스 등)의 이름과 위치를 변수로 선언합니다. \n",
    "\n",
    "- **목적:**\n",
    "    - CLI 명령어 실행 시 반복적으로 사용할 값(리소스명, 지역 등)을 변수로 지정하여, 실습 과정에서 일관성 있게 활용할 수 있도록 합니다.\n",
    "    - 변수만 수정하면 이후 셀의 명령어들이 자동으로 해당 값으로 반영되어 편리합니다.\n",
    "- **사용 방법:**\n",
    "    - 실습 환경에 맞게 변수값(예: 리소스 그룹명, 지역, 스토리지 계정명 등)을 수정하세요.\n",
    "    - 이후 셀에서 `$변수명` 형태로 참조되어 CLI 명령어에 자동으로 적용됩니다.\n",
    "- **예시:**\n",
    "    - `RESOURCE_GROUP=\"myResourceGroup\"` → 실제 본인이 생성한 리소스 그룹명으로 변경\n",
    "    - `LOCATION=\"koreacentral\"` → 원하는 Azure 지역으로 변경\n",
    "\n",
    "> ⚠️ 변수값을 잘못 입력하면 리소스 생성이나 명령어 실행이 실패할 수 있으니, Azure Portal에서 실제 리소스명을 확인 후 입력하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ecbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure 리소스 변수 선언 (실행 전 변수값을 원하는 값으로 수정하세요)\n",
    "RESOURCE_GROUP=\"myResourceGroup\"\n",
    "LOCATION=\"koreacentral\"\n",
    "STORAGE_ACCOUNT=\"myraglabstorage9556\"\n",
    "CONTAINER_NAME=\"json-container\"\n",
    "SEARCH_SERVICE=\"my-rag-lab-search\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da52ba2",
   "metadata": {},
   "source": [
    "> ⚠️ **참고:** 3번 노트북(03-deploying-to-aks-using-docker-and-acr.ipynb)에서 이미 리소스 그룹을 생성했다면, 아래 셀은 실행하지 않고 스킵합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e15be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 리소스 그룹 생성 (필수 단계 아님)\n",
    "!az group create --name $RESOURCE_GROUP --location $LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19094ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{| Finished ..\n",
      "  \"accessTier\": \"Hot\",\n",
      "  \"accountMigrationInProgress\": null,\n",
      "  \"allowBlobPublicAccess\": false,\n",
      "  \"allowCrossTenantReplication\": false,\n",
      "  \"allowSharedKeyAccess\": null,\n",
      "  \"allowedCopyScope\": null,\n",
      "  \"azureFilesIdentityBasedAuthentication\": null,\n",
      "  \"blobRestoreStatus\": null,\n",
      "  \"creationTime\": \"2025-05-15T00:26:03.086819+00:00\",\n",
      "  \"customDomain\": null,\n",
      "  \"defaultToOAuthAuthentication\": null,\n",
      "  \"dnsEndpointType\": null,\n",
      "  \"enableExtendedGroups\": null,\n",
      "  \"enableHttpsTrafficOnly\": true,\n",
      "  \"enableNfsV3\": null,\n",
      "  \"encryption\": {\n",
      "    \"encryptionIdentity\": null,\n",
      "    \"keySource\": \"Microsoft.Storage\",\n",
      "    \"keyVaultProperties\": null,\n",
      "    \"requireInfrastructureEncryption\": null,\n",
      "    \"services\": {\n",
      "      \"blob\": {\n",
      "        \"enabled\": true,\n",
      "        \"keyType\": \"Account\",\n",
      "        \"lastEnabledTime\": \"2025-05-15T00:26:03.180586+00:00\"\n",
      "      },\n",
      "      \"file\": {\n",
      "        \"enabled\": true,\n",
      "        \"keyType\": \"Account\",\n",
      "        \"lastEnabledTime\": \"2025-05-15T00:26:03.180586+00:00\"\n",
      "      },\n",
      "      \"queue\": null,\n",
      "      \"table\": null\n",
      "    }\n",
      "  },\n",
      "  \"extendedLocation\": null,\n",
      "  \"failoverInProgress\": null,\n",
      "  \"geoReplicationStats\": null,\n",
      "  \"id\": \"/subscriptions/49a89096-a0ae-4e59-816b-dcb0a6fe9168/resourceGroups/myResourceGroup/providers/Microsoft.Storage/storageAccounts/myraglabstorage9556\",\n",
      "  \"identity\": null,\n",
      "  \"immutableStorageWithVersioning\": null,\n",
      "  \"isHnsEnabled\": null,\n",
      "  \"isLocalUserEnabled\": null,\n",
      "  \"isSftpEnabled\": null,\n",
      "  \"isSkuConversionBlocked\": null,\n",
      "  \"keyCreationTime\": {\n",
      "    \"key1\": \"2025-05-15T00:26:03.164968+00:00\",\n",
      "    \"key2\": \"2025-05-15T00:26:03.164968+00:00\"\n",
      "  },\n",
      "  \"keyPolicy\": null,\n",
      "  \"kind\": \"StorageV2\",\n",
      "  \"largeFileSharesState\": null,\n",
      "  \"lastGeoFailoverTime\": null,\n",
      "  \"location\": \"koreacentral\",\n",
      "  \"minimumTlsVersion\": \"TLS1_0\",\n",
      "  \"name\": \"myraglabstorage9556\",\n",
      "  \"networkRuleSet\": {\n",
      "    \"bypass\": \"AzureServices\",\n",
      "    \"defaultAction\": \"Allow\",\n",
      "    \"ipRules\": [],\n",
      "    \"ipv6Rules\": [],\n",
      "    \"resourceAccessRules\": null,\n",
      "    \"virtualNetworkRules\": []\n",
      "  },\n",
      "  \"primaryEndpoints\": {\n",
      "    \"blob\": \"https://myraglabstorage9556.blob.core.windows.net/\",\n",
      "    \"dfs\": \"https://myraglabstorage9556.dfs.core.windows.net/\",\n",
      "    \"file\": \"https://myraglabstorage9556.file.core.windows.net/\",\n",
      "    \"internetEndpoints\": null,\n",
      "    \"microsoftEndpoints\": null,\n",
      "    \"queue\": \"https://myraglabstorage9556.queue.core.windows.net/\",\n",
      "    \"table\": \"https://myraglabstorage9556.table.core.windows.net/\",\n",
      "    \"web\": \"https://myraglabstorage9556.z12.web.core.windows.net/\"\n",
      "  },\n",
      "  \"primaryLocation\": \"koreacentral\",\n",
      "  \"privateEndpointConnections\": [],\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"publicNetworkAccess\": null,\n",
      "  \"resourceGroup\": \"myResourceGroup\",\n",
      "  \"routingPreference\": null,\n",
      "  \"sasPolicy\": null,\n",
      "  \"secondaryEndpoints\": null,\n",
      "  \"secondaryLocation\": null,\n",
      "  \"sku\": {\n",
      "    \"name\": \"Standard_LRS\",\n",
      "    \"tier\": \"Standard\"\n",
      "  },\n",
      "  \"statusOfPrimary\": \"available\",\n",
      "  \"statusOfSecondary\": null,\n",
      "  \"storageAccountSkuConversionStatus\": null,\n",
      "  \"tags\": {},\n",
      "  \"type\": \"Microsoft.Storage/storageAccounts\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 2-1. Blob Storage 계정 생성\n",
    "!az storage account create \\\n",
    "  --name $STORAGE_ACCOUNT \\\n",
    "  --resource-group $RESOURCE_GROUP \\\n",
    "  --location $LOCATION \\\n",
    "  --sku Standard_LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb690c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 2-2. Blob Storage 컨테이너 생성 (Azure AD 권한 사용)\n",
    "!az storage container create \\\n",
    "  --account-name $STORAGE_ACCOUNT \\\n",
    "  --name $CONTAINER_NAME \\\n",
    "  --auth-mode login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d72307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결 문자열 확인 (환경 변수에 사용)\n",
    "!az storage account show-connection-string \\\n",
    "  --name $STORAGE_ACCOUNT \\\n",
    "  --resource-group $RESOURCE_GROUP \\\n",
    "  --query connectionString --output tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5093f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"authOptions\": {\n",
      "    \"apiKeyOnly\": {}\n",
      "  },\n",
      "  \"disableLocalAuth\": false,\n",
      "  \"encryptionWithCmk\": {\n",
      "    \"encryptionComplianceStatus\": \"Compliant\",\n",
      "    \"enforcement\": \"Unspecified\"\n",
      "  },\n",
      "  \"hostingMode\": \"default\",\n",
      "  \"id\": \"/subscriptions/49a89096-a0ae-4e59-816b-dcb0a6fe9168/resourceGroups/myResourceGroup/providers/Microsoft.Search/searchServices/my-rag-lab-search\",\n",
      "  \"location\": \"Korea Central\",\n",
      "  \"name\": \"my-rag-lab-search\",\n",
      "  \"networkRuleSet\": {\n",
      "    \"ipRules\": []\n",
      "  },\n",
      "  \"partitionCount\": 1,\n",
      "  \"privateEndpointConnections\": [],\n",
      "  \"provisioningState\": \"succeeded\",\n",
      "  \"publicNetworkAccess\": \"Enabled\",\n",
      "  \"replicaCount\": 1,\n",
      "  \"resourceGroup\": \"myResourceGroup\",\n",
      "  \"semanticSearch\": \"free\",\n",
      "  \"sharedPrivateLinkResources\": [],\n",
      "  \"sku\": {\n",
      "    \"name\": \"basic\"\n",
      "  },\n",
      "  \"status\": \"running\",\n",
      "  \"statusDetails\": \"\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"Microsoft.Search/searchServices\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 3. Azure AI Search 서비스 생성\n",
    "!az search service create \\\n",
    "  --name $SEARCH_SERVICE \\\n",
    "  --resource-group $RESOURCE_GROUP \\\n",
    "  --location $LOCATION \\\n",
    "  --sku basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7020639",
   "metadata": {},
   "source": [
    "### [중요] `.env` 파일에 이 노트북을 위한 추가 환경 변수 설정\n",
    "\n",
    "`README.md` 파일에 `.env` 파일 생성 및 Azure OpenAI 관련 기본 환경 변수 설정에 대한 안내가 이미 포함되어 있습니다. 이 노트북을 실행하기 위해서는 해당 기본 설정 외에 Azure AI Search 및 Azure Blob Storage 관련 환경 변수를 `.env` 파일에 추가해야 합니다.\n",
    "\n",
    "**이 노트북에 필요한 추가 환경 변수 예시:**\n",
    "\n",
    "```env\n",
    "# --- README.md에 명시된 Azure OpenAI 변수들 ---\n",
    "\n",
    "# AZURE_OPENAI_ENDPOINT=\"your_openai_endpoint_here\"\n",
    "# AZURE_OPENAI_API_KEY=\"your_openai_api_key_here\"\n",
    "# AZURE_OPENAI_API_VERSION=\"2024-02-01\"\n",
    "# AZURE_OPENAI_DEPLOYMENT_EMBEDDING_NAME=\"your_embedding_deployment_name_here\"\n",
    "# AZURE_OPENAI_DEPLOYMENT_NAME=\"your_chat_deployment_name_here\"\n",
    "\n",
    "# --- 이 노트북을 위한 추가 변수 ---\n",
    "\n",
    "# Azure AI Search\n",
    "AZURE_SEARCH_ENDPOINT=\"your_search_endpoint_here\"\n",
    "AZURE_SEARCH_API_KEY=\"your_search_api_key_here\"\n",
    "AZURE_SEARCH_INDEX_NAME=\"your_search_index_name_here\"\n",
    "\n",
    "# Azure Blob Storage\n",
    "AZURE_BLOB_CONNECTION_STRING=\"your_blob_connection_string_here\"\n",
    "```\n",
    "\n",
    "*   **확인:** `README.md`의 안내에 따라 Azure OpenAI 관련 환경 변수(`AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI_API_KEY` 등)가 이미 `.env` 파일에 설정되어 있는지 확인하세요.\n",
    "*   위 목록에서 `#`으로 시작하는 줄은 주석이며, 실제 값으로 `\"your_..._here\"` 부분을 교체해야 합니다.\n",
    "*   `python-dotenv` 라이브러리를 사용하여 이 변수들을 로드하는 방법은 `README.md` 또는 이 노트북의 다른 Python 셀들을 참고하세요. 대부분의 코드 셀 시작 부분에 `load_dotenv()`가 이미 포함되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee7fd4",
   "metadata": {},
   "source": [
    "### Azure AI Search의 Endpoint와 API Key 확인 방법\n",
    "\n",
    "- **AZURE_SEARCH_ENDPOINT**: Azure Portal에서 생성한 Azure AI Search 리소스의 개요(Overview) 페이지에서 'URL' 항목을 확인할 수 있습니다. 예시: `https://<search-service-name>.search.windows.net`\n",
    "- **AZURE_SEARCH_API_KEY**: Azure Portal에서 해당 Search 리소스 > '키(Key)' 메뉴에서 '관리 키(Admin keys)'를 확인할 수 있습니다.\n",
    "\n",
    "또는 아래 CLI 명령어로도 확인할 수 있습니다:\n",
    "\n",
    "```bash\n",
    "# 관리 키 확인\n",
    "az search admin-key show --service-name <SEARCH_SERVICE> --resource-group <RESOURCE_GROUP>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd7d83",
   "metadata": {},
   "source": [
    "### [중요] 패키지 설치 및 커널 재시작 안내\n",
    "\n",
    "- 아래 셀을 실행하여 필요한 라이브러리를 설치하세요.\n",
    "- 설치가 완료된 후에는 **커널을 반드시 재시작**해야 모든 패키지가 정상적으로 인식됩니다.\n",
    "- 커널 재시작 방법: 메뉴에서 'Runtime' > 'Restart Kernel' 또는 상단의 재시작 아이콘 클릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b60ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.5.6)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.77.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: azure-core in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.33.0)\n",
      "Requirement already satisfied: azure-search-documents in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (11.5.2)\n",
      "Requirement already satisfied: azure-storage-blob in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (12.25.1)\n",
      "Requirement already satisfied: autogen-ext[azure,openai] in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.5.6)\n",
      "Requirement already satisfied: autogen-core==0.5.6 in ./.venv/lib/python3.12/site-packages (from autogen-agentchat->-r requirements.txt (line 1)) (0.5.6)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in ./.venv/lib/python3.12/site-packages (from autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in ./.venv/lib/python3.12/site-packages (from autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (1.32.1)\n",
      "Requirement already satisfied: pillow>=11.0.0 in ./.venv/lib/python3.12/site-packages (from autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (11.2.1)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in ./.venv/lib/python3.12/site-packages (from autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in ./.venv/lib/python3.12/site-packages (from autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (2.11.4)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.12/site-packages (from autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (4.13.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: azure-ai-inference>=1.0.0b7 in ./.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]->-r requirements.txt (line 2)) (1.0.0b9)\n",
      "Requirement already satisfied: azure-ai-projects>=1.0.0b8 in ./.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]->-r requirements.txt (line 2)) (1.0.0b10)\n",
      "Requirement already satisfied: azure-identity in ./.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]->-r requirements.txt (line 2)) (1.21.0)\n",
      "Requirement already satisfied: aiofiles in ./.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]->-r requirements.txt (line 2)) (24.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken->-r requirements.txt (line 6)) (2024.11.6)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.12/site-packages (from azure-core->-r requirements.txt (line 7)) (1.17.0)\n",
      "Requirement already satisfied: azure-common>=1.1 in ./.venv/lib/python3.12/site-packages (from azure-search-documents->-r requirements.txt (line 8)) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in ./.venv/lib/python3.12/site-packages (from azure-search-documents->-r requirements.txt (line 8)) (0.7.2)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in ./.venv/lib/python3.12/site-packages (from azure-storage-blob->-r requirements.txt (line 9)) (44.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.12/site-packages (from cryptography>=2.1.4->azure-storage-blob->-r requirements.txt (line 9)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->-r requirements.txt (line 9)) (2.22)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (3.21.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.5.6->autogen-agentchat->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in ./.venv/lib/python3.12/site-packages (from azure-identity->autogen-ext[azure,openai]->-r requirements.txt (line 2)) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in ./.venv/lib/python3.12/site-packages (from azure-identity->autogen-ext[azure,openai]->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->autogen-ext[azure,openai]->-r requirements.txt (line 2)) (2.10.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 파이썬 패키지 설치\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa31ab1",
   "metadata": {},
   "source": [
    "## 2. JSON 데이터 준비 및 업로드\n",
    "\n",
    "1. JSON 파일을 준비합니다. (예: 각 문서가 하나의 JSON 오브젝트로 구성된 리스트)\n",
    "2. Azure Blob Storage에 JSON 파일을 업로드합니다.\n",
    "\n",
    "아래 코드는 JSON 파일을 Azure Blob Storage에 업로드하는 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3fd5f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일 업로드 성공\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "blob_conn_str = os.getenv(\"AZURE_BLOB_CONNECTION_STRING\")\n",
    "container_name = \"json-container\"\n",
    "json_path = \"./sample.json\"  # 실습용 JSON 파일 경로\n",
    "\n",
    "if not blob_conn_str:\n",
    "    raise ValueError(\"AZURE_BLOB_CONNECTION_STRING 환경변수가 설정되지 않았습니다.\")\n",
    "\n",
    "try:\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(blob_conn_str)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    # 컨테이너가 없으면 생성\n",
    "    try:\n",
    "        container_client.create_container()\n",
    "    except Exception:\n",
    "        pass  # 이미 있으면 무시\n",
    "\n",
    "    with open(json_path, \"rb\") as data:\n",
    "        container_client.upload_blob(name=\"sample.json\", data=data, overwrite=True)\n",
    "    print(\"JSON 파일 업로드 성공\")\n",
    "except Exception as e:\n",
    "    print(f\"JSON 파일 업로드 실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a481f4",
   "metadata": {},
   "source": [
    "## 3. Azure AI Search 인덱스 생성\n",
    "\n",
    "1. Azure AI Search 인덱스 스키마(필드: id, content, metadata, embedding 등)를 정의합니다.\n",
    "2. Azure AI Search에 인덱스를 생성합니다.\n",
    "\n",
    "아래 코드는 Azure AI Search에 인덱스를 생성하는 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35981d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 생성 완료: json-index\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SearchIndex,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters\n",
    ")\n",
    "\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_EMBEDDING_NAME\")\n",
    "deployment_model = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_EMBEDDING_NAME\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=AzureKeyCredential(search_key))\n",
    "\n",
    "# 벡터 검색 프로필 및 알고리즘 구성\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\")\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "            vectorizer_name=\"myVectorizer\"\n",
    "        )\n",
    "    ],\n",
    "    vectorizers=[\n",
    "        AzureOpenAIVectorizer(\n",
    "            vectorizer_name=\"myVectorizer\",\n",
    "            parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_embedding_deployment,\n",
    "                model_name=embedding_model,\n",
    "                api_key=azure_openai_key\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SimpleField(name=\"content\", type=SearchFieldDataType.String, searchable=True),\n",
    "    SimpleField(name=\"metadata\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchField(\n",
    "        name=\"embedding\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=3072,  # text-embedding-3-large 차원수\n",
    "        vector_search_profile_name=\"myHnswProfile\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n",
    "try:\n",
    "    index_client.create_or_update_index(index)\n",
    "    print(f\"인덱스 생성 완료: {index_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"인덱스 생성 오류 또는 이미 존재: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a81cc1",
   "metadata": {},
   "source": [
    "## 4. JSON 데이터 인덱싱\n",
    "\n",
    "1. JSON에서 텍스트(content 필드 등)를 추출합니다.\n",
    "2. 추출한 텍스트로 임베딩을 생성합니다.\n",
    "3. 텍스트와 임베딩을 Azure AI Search 인덱스에 저장합니다.\n",
    "\n",
    "아래 코드는 Azure Blob Storage와 Search SDK를 활용한 전체 예시입니다.\n",
    "\n",
    "> **참고:** 벡터 검색을 위해 embedding 필드를 `Collection(SearchFieldDataType.Single)` 타입으로 추가해야 하며, JSON에서 텍스트를 추출한 후 임베딩을 생성하여 인덱스에 저장하는 전체 과정을 코드로 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4253fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 업로드 완료: uniqlo001\n",
      "문서 업로드 완료: uniqlo002\n",
      "문서 업로드 완료: uniqlo003\n",
      "문서 업로드 완료: uniqlo004\n",
      "문서 업로드 완료: uniqlo005\n",
      "문서 업로드 완료: uniqlo006\n",
      "문서 업로드 완료: uniqlo007\n",
      "문서 업로드 완료: uniqlo008\n",
      "문서 업로드 완료: uniqlo009\n",
      "문서 업로드 완료: uniqlo010\n",
      "문서 업로드 완료: uniqlo011\n",
      "문서 업로드 완료: uniqlo012\n",
      "문서 업로드 완료: uniqlo013\n",
      "문서 업로드 완료: uniqlo014\n",
      "문서 업로드 완료: uniqlo015\n",
      "문서 업로드 완료: uniqlo016\n",
      "문서 업로드 완료: uniqlo017\n",
      "문서 업로드 완료: uniqlo018\n",
      "문서 업로드 완료: uniqlo019\n",
      "문서 업로드 완료: uniqlo020\n",
      "문서 업로드 완료: uniqlo021\n",
      "문서 업로드 완료: uniqlo022\n",
      "문서 업로드 완료: uniqlo023\n",
      "문서 업로드 완료: uniqlo024\n",
      "문서 업로드 완료: uniqlo025\n",
      "문서 업로드 완료: uniqlo026\n",
      "문서 업로드 완료: uniqlo027\n",
      "문서 업로드 완료: uniqlo028\n",
      "문서 업로드 완료: uniqlo029\n",
      "문서 업로드 완료: uniqlo030\n",
      "문서 업로드 완료: uniqlo031\n",
      "문서 업로드 완료: uniqlo032\n",
      "문서 업로드 완료: uniqlo033\n",
      "문서 업로드 완료: uniqlo034\n",
      "문서 업로드 완료: uniqlo035\n",
      "문서 업로드 완료: uniqlo036\n",
      "문서 업로드 완료: uniqlo037\n",
      "문서 업로드 완료: uniqlo038\n",
      "문서 업로드 완료: uniqlo039\n",
      "문서 업로드 완료: uniqlo040\n",
      "문서 업로드 완료: uniqlo041\n",
      "문서 업로드 완료: uniqlo042\n",
      "문서 업로드 완료: uniqlo043\n",
      "문서 업로드 완료: uniqlo044\n",
      "문서 업로드 완료: uniqlo045\n",
      "문서 업로드 완료: uniqlo046\n",
      "문서 업로드 완료: uniqlo047\n",
      "문서 업로드 완료: uniqlo048\n",
      "문서 업로드 완료: uniqlo049\n",
      "문서 업로드 완료: uniqlo050\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_EMBEDDING_NAME\", \"text-embedding-3-large\")\n",
    "\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "\n",
    "# JSON 데이터 로드 (리스트 형태로 파싱)\n",
    "json_docs = []\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    try:\n",
    "        json_docs = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"JSON 파일 파싱 오류: {e}\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=openai_key,\n",
    "    api_version=openai_api_version,\n",
    "    azure_endpoint=openai_endpoint\n",
    ")\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint, \n",
    "    index_name=index_name, \n",
    "    credential=AzureKeyCredential(search_key)\n",
    ")\n",
    "\n",
    "for doc in json_docs:\n",
    "    content = doc.get(\"content\", \"\")\n",
    "    metadata = doc.get(\"metadata\", \"\")\n",
    "    doc_id = doc.get(\"id\", None) or str(hash(content))\n",
    "    embedding_response = client.embeddings.create(\n",
    "        input=content,\n",
    "        model=embedding_model\n",
    "    )\n",
    "    embedding = embedding_response.data[0].embedding\n",
    "    index_doc = {\"id\": doc_id, \"content\": content, \"metadata\": metadata, \"embedding\": embedding}\n",
    "    try:\n",
    "        search_client.upload_documents(documents=[index_doc])\n",
    "        print(f\"문서 업로드 완료: {doc_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"업로드 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca693b6",
   "metadata": {},
   "source": [
    "## 5. 자연어 쿼리로 검색 및 유사 문서 찾기\n",
    "\n",
    "- 사용자의 질문을 임베딩으로 변환하고, Azure AI Search에서 벡터 유사도 기반으로 관련 문서를 검색합니다.\n",
    "\n",
    "아래는 쿼리 임베딩 생성 및 검색 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc33b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Search Result ---\n",
      "ID: uniqlo023\n",
      "Content: 이지 쇼트 팬츠 | 남성, 밴딩, 쿨링, 여름 필수템. 허리 밴딩과 쿨링 소재로 무더운 여름에도 편안하게 입을 수 있습니다. 다양한 상의와 매치해 캐주얼하게 연출할 수 있습니다....\n",
      "Metadata: 유니클로, 팬츠, 쇼트, 남성, 쿨링, 여름\n",
      "---------------------\n",
      "\n",
      "--- Search Result ---\n",
      "ID: uniqlo048\n",
      "Content: 에어리즘 스트레치 쇼트 팬츠 | 남성, 쿨링, 여름 필수템. 신축성과 쿨링 기능으로 무더운 여름에도 쾌적하게 입을 수 있습니다. 다양한 상의와 매치해 캐주얼하게 연출할 수 있습니다....\n",
      "Metadata: 유니클로, 팬츠, 쇼트, 남성, 쿨링, 여름\n",
      "---------------------\n",
      "\n",
      "--- Search Result ---\n",
      "ID: uniqlo008\n",
      "Content: 프리미엄 리넨 셔츠 | 남성, 시원한 린넨, 여름 인기. 통기성이 좋아 무더운 날씨에도 쾌적하게 입을 수 있습니다. 자연스러운 핏으로 세련된 스타일을 연출합니다....\n",
      "Metadata: 유니클로, 셔츠, 린넨, 남성, 여름\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery # VectorQuery에서 변경\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_EMBEDDING_NAME\")\n",
    "deployment_model = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=openai_key,\n",
    "    api_version=openai_api_version,\n",
    "    azure_endpoint=openai_endpoint\n",
    ")\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint, \n",
    "    index_name=index_name, \n",
    "    credential=AzureKeyCredential(search_key)\n",
    ")\n",
    "\n",
    "query_text = \"남성용으로 여름에 시원하게 입을 수 있는 옷 추천해줘\" # 사용자 질문\n",
    "results = [] # results 변수를 try 블록 외부에서 초기화\n",
    "\n",
    "try:\n",
    "    # 질문을 임베딩으로 변환\n",
    "    query_embedding = client.embeddings.create(\n",
    "        input=query_text,\n",
    "        model=embedding_model\n",
    "    ).data[0].embedding\n",
    "\n",
    "    # VectorizedQuery 객체 생성 (참조 코드에 따라 수정)\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=query_embedding, \n",
    "        k_nearest_neighbors=50, # 참조 코드에 따라 50으로 변경\n",
    "        fields=\"embedding\"  # 노트북 인덱스의 필드명 사용\n",
    "    )\n",
    "\n",
    "    # 검색 실행 (참조 코드에 따라 select 및 top 파라미터 추가/수정)\n",
    "    search_results_iterator = search_client.search(\n",
    "        search_text=None,  \n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\", \"content\", \"metadata\"], # 반환할 필드 선택\n",
    "        top=3  # 상위 3개 결과 요청\n",
    "    )\n",
    "    results = list(search_results_iterator) # 이터레이터를 즉시 리스트로 변환하여 results에 저장\n",
    "\n",
    "    # 결과 처리 (선택된 필드들을 출력하도록 수정)\n",
    "    found_any_results = False\n",
    "    for result_document in results: # 이제 results는 리스트입니다.\n",
    "        found_any_results = True\n",
    "        print(\"\\n--- Search Result ---\")\n",
    "        print(f\"ID: {result_document.get('id')}\")\n",
    "        # content 필드가 없을 경우를 대비해 .get() 사용 및 길이 제한\n",
    "        content_snippet = result_document.get('content', '')\n",
    "        print(f\"Content: {content_snippet[:150]}...\") \n",
    "        print(f\"Metadata: {result_document.get('metadata')}\")\n",
    "        print(\"---------------------\")\n",
    "    \n",
    "    if not found_any_results:\n",
    "        print(\"\\nNo documents found matching your query.\")\n",
    "\n",
    "except Exception as e: \n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351235c",
   "metadata": {},
   "source": [
    "## 6. RAG(Retrieval Augmented Generation) 구현\n",
    "\n",
    "5번 예제에서 검색된 문서를 활용하여 RAG 파이프라인을 구축할 수 있습니다. RAG는 검색된 정보를 바탕으로 LLM(Large Language Model)이 보다 정확하고 풍부한 답변을 생성하도록 돕는 기술입니다.\n",
    "\n",
    "**RAG 구현 단계:**\n",
    "\n",
    "1.  **사용자 질문 접수:** 사용자의 질문을 받습니다. (5번 예제의 `query_text`)\n",
    "2.  **관련 문서 검색:**\n",
    "    *   사용자 질문을 임베딩으로 변환합니다.\n",
    "    *   Azure AI Search를 사용하여 관련성이 높은 문서를 검색합니다. (5번 예제의 `search_client.search(...)` 결과)\n",
    "3.  **프롬프트 구성:**\n",
    "    *   검색된 문서의 내용(예: `result_document['content']`)을 컨텍스트로 활용합니다.\n",
    "    *   사용자의 원본 질문과 검색된 컨텍스트를 결합하여 LLM에 전달할 프롬프트를 생성합니다. 예를 들어, 다음과 같은 형식을 사용할 수 있습니다:\n",
    "        ```\n",
    "        다음 컨텍스트를 참고하여 질문에 답변해주세요.\n",
    "        \n",
    "        컨텍스트:\n",
    "        [검색된 문서 1의 내용]\n",
    "        [검색된 문서 2의 내용]\n",
    "        ...\n",
    "        \n",
    "        질문: [사용자의 원본 질문]\n",
    "        ```\n",
    "4.  **LLM을 통한 답변 생성:**\n",
    "    *   구성된 프롬프트를 Azure OpenAI의 언어 모델(예: `gpt-4.1-mini`, `gpt-4o-mini`)에 전달합니다.\n",
    "    *   LLM은 제공된 컨텍스트를 기반으로 사용자의 질문에 대한 답변을 생성합니다.\n",
    "5.  **답변 반환:** 생성된 답변을 사용자에게 제공합니다.\n",
    "\n",
    "**구현 시 고려사항:**\n",
    "\n",
    "*   **컨텍스트 길이:** LLM에 전달하는 컨텍스트의 길이는 모델의 토큰 제한을 고려해야 합니다. 필요시 검색된 문서의 내용을 요약하거나, 가장 관련성 높은 부분만 추출하여 사용합니다.\n",
    "*   **프롬프트 엔지니어링:** LLM이 컨텍스트를 효과적으로 활용하고 원하는 답변을 생성하도록 프롬프트를 잘 설계하는 것이 중요합니다.\n",
    "*   **반복 및 개선:** 검색 결과가 만족스럽지 않거나 LLM의 답변 품질이 낮을 경우, 검색 쿼리, 임베딩 모델, 프롬프트 등을 조정하며 반복적으로 개선합니다.\n",
    "\n",
    "이 가이드를 바탕으로 5번에서 구현한 벡터 검색 결과를 활용하여 RAG 기반의 질의응답 시스템을 구축해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c273dd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 구성된 프롬프트 ---\n",
      "다음 컨텍스트를 참고하여 질문에 답변해주세요.\n",
      "\n",
      "컨텍스트:\n",
      "이지 쇼트 팬츠 | 남성, 밴딩, 쿨링, 여름 필수템. 허리 밴딩과 쿨링 소재로 무더운 여름에도 편안하게 입을 수 있습니다. 다양한 상의와 매치해 캐주얼하게 연출할 수 있습니다.\n",
      "\n",
      "에어리즘 스트레치 쇼트 팬츠 | 남성, 쿨링, 여름 필수템. 신축성과 쿨링 기능으로 무더운 여름에도 쾌적하게 입을 수 있습니다. 다양한 상의와 매치해 캐주얼하게 연출할 수 있습니다.\n",
      "\n",
      "프리미엄 리넨 셔츠 | 남성, 시원한 린넨, 여름 인기. 통기성이 좋아 무더운 날씨에도 쾌적하게 입을 수 있습니다. 자연스러운 핏으로 세련된 스타일을 연출합니다.\n",
      "\n",
      "질문: 남성용으로 여름에 시원하게 입을 수 있는 옷 추천해줘\n",
      "\n",
      "---------------------\n",
      "\n",
      "LLM 답변: 여름에 남성용으로 시원하게 입을 수 있는 옷으로는 다음을 추천합니다.\n",
      "\n",
      "1. 이지 쇼트 팬츠: 허리 밴딩과 쿨링 소재로 편안하고 시원하게 착용할 수 있어 무더운 여름에 적합합니다.\n",
      "\n",
      "2. 에어리즘 스트레치 쇼트 팬츠: 신축성과 쿨링 기능이 있어 쾌적한 착용감을 제공합니다.\n",
      "\n",
      "3. 프리미엄 리넨 셔츠: 통기성이 뛰어난 린넨 소재로 무더운 날씨에도 쾌적하며 자연스러운 핏으로 세련된 스타일을 연출할 수 있습니다.\n",
      "\n",
      "이 제품들은 모두 여름에 캐주얼하게 매치하기 좋은 아이템입니다.\n"
     ]
    }
   ],
   "source": [
    "# (이전 셀에서 client, search_client, query_text, results 등이 정의되었다고 가정)\n",
    "\n",
    "# 프롬프트 구성\n",
    "\n",
    "try:\n",
    "    # `results` 변수가 정의되지 않았다면 아래 접근 시 NameError 발생\n",
    "    if results is None: # 추가된 체크: results가 None인지 확인\n",
    "        raise ValueError(\"`results` 변수가 None입니다. 5번 '자연어 쿼리로 검색' 셀의 실행을 확인해주세요.\")\n",
    "\n",
    "    retrieved_context = \"\\n\\n\".join([doc.get('content', '') for doc in results])\n",
    "\n",
    "    prompt = f\"\"\"다음 컨텍스트를 참고하여 질문에 답변해주세요.\n",
    "\n",
    "컨텍스트:\n",
    "{retrieved_context}\n",
    "\n",
    "질문: {query_text}\n",
    "\"\"\"\n",
    "\n",
    "    print(\"--- 구성된 프롬프트 ---\")\n",
    "    print(prompt)\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # LLM을 통한 답변 생성 (Azure OpenAI SDK 실제 호출)\n",
    "    from openai import AzureOpenAI\n",
    "    openai_client = AzureOpenAI(\n",
    "        api_key=openai_key,\n",
    "        api_version=openai_api_version,\n",
    "        azure_endpoint=openai_endpoint\n",
    "    )\n",
    "\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=deployment_model,  # 사용자의 모델 배포명으로 필요시 변경\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"당신은 유용한 AI 어시스턴트입니다.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    generated_answer = completion.choices[0].message.content\n",
    "    print(f\"\\nLLM 답변: {generated_answer}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}.\\n이전 셀(특히 5번 '자연어 쿼리로 검색' 셀)의 실행 상태, results 변수, API 키 및 엔드포인트 설정을 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a687cc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "이 노트북에서는 JSON 데이터를 Azure AI Search에 업로드하고, OpenAI 임베딩을 활용해 벡터 검색을 구현하는 RAG 실습을 진행했습니다.\n",
    "\n",
    "- Azure 리소스 준비 → JSON 업로드 및 인덱싱 → 임베딩 생성 및 저장 → 벡터 검색\n",
    "- 실제 서비스 적용 시, 보안, 대용량 처리, 인덱스 관리 등 추가 고려가 필요합니다.\n",
    "\n",
    "### 참고 자료\n",
    "- [Azure AI Search 공식 문서](https://learn.microsoft.com/azure/search/)\n",
    "- [Azure OpenAI Service 공식 문서](https://learn.microsoft.com/azure/cognitive-services/openai/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
